[GPT]
CONTEXT_SIZE = 128
VOCAB_SIZE = 300
EMBEDDING_DIM = 64
NUM_HEADS = 4
NUM_TRANSFORMER_BLOCK = 4


[TRAIN]
DATASET_PATH = input.txt
SAVED_WEIGHTS_PATH = gpt-weights.pth
BATCH_SIZE = 32
LEARNING_RATE = 1e-3
EPOCHS = 200
LOAD_WEIGHTS = TRUE

[TOKENIZER]
TOKENIZER_SAVE_PATH = tokenizer.pkl